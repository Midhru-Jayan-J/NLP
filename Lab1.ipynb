{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Input\n",
    "sentence= input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ddf8a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing in NLTK involves cleaning and preparing raw text data for analysis. It helps in handling symbols like \"@\", \"#\", or \"&\", numbers like \"123\" or \"99.9\", and abbreviations like \"U.S.A.\" or \"etc.\" Common steps include tokenization, removing unwanted characters, and normalizing text. This ensures better performance in tasks like sentiment analysis, classification, or language modeling.\n"
     ]
    }
   ],
   "source": [
    "print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b9d586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing in NLTK involves cleaning and preparing raw text data for analysis. It helps in handling symbols like \"@\", \"#\", or \"&\", numbers like \"123\" or \"99.9\", and abbreviations like \"U.S.A.\" or \"etc.\" Common steps include tokenization, removing unwanted characters, and normalizing text. This ensures better performance in tasks like sentiment analysis, classification, or language modeling.\n"
     ]
    }
   ],
   "source": [
    "# 2. Basic Preprocess - removing extra spaces\n",
    "cleaned_text=\" \".join(sentence.split())\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d6cb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing in nltk involves cleaning and preparing raw text data for analysis. it helps in handling symbols like \"@\", \"#\", or \"&\", numbers like \"123\" or \"99.9\", and abbreviations like \"u.s.a.\" or \"etc.\" common steps include tokenization, removing unwanted characters, and normalizing text. this ensures better performance in tasks like sentiment analysis, classification, or language modeling.\n"
     ]
    }
   ],
   "source": [
    "# 3.Lower Case\n",
    "lower_text=cleaned_text.lower()\n",
    "print(lower_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a338cbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preprocessing', 'in', 'nltk', 'involves', 'cleaning', 'and', 'preparing', 'raw', 'text', 'data', 'for', 'analysis', '.', 'it', 'helps', 'in', 'handling', 'symbols', 'like', '``', '@', \"''\", ',', '``', '#', \"''\", ',', 'or', '``', '&', \"''\", ',', 'numbers', 'like', '``', '123', \"''\", 'or', '``', '99.9', \"''\", ',', 'and', 'abbreviations', 'like', '``', 'u.s.a.', \"''\", 'or', '``', 'etc', '.', \"''\", 'common', 'steps', 'include', 'tokenization', ',', 'removing', 'unwanted', 'characters', ',', 'and', 'normalizing', 'text', '.', 'this', 'ensures', 'better', 'performance', 'in', 'tasks', 'like', 'sentiment', 'analysis', ',', 'classification', ',', 'or', 'language', 'modeling', '.']\n"
     ]
    }
   ],
   "source": [
    "# 4. Tokenization \n",
    "from nltk.tokenize import word_tokenize,sent_tokenize #word - for each word , sent-for each sentence\n",
    "tokens=word_tokenize(lower_text)\n",
    "print(tokens)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c86c8b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preprocessing', 'in', 'nltk', 'involves', 'cleaning', 'and', 'preparing', 'raw', 'text', 'data', 'for', 'analysis', 'it', 'helps', 'in', 'handling', 'symbols', 'like', '``', \"''\", '``', \"''\", 'or', '``', \"''\", 'numbers', 'like', '``', '123', \"''\", 'or', '``', '99.9', \"''\", 'and', 'abbreviations', 'like', '``', 'u.s.a.', \"''\", 'or', '``', 'etc', \"''\", 'common', 'steps', 'include', 'tokenization', 'removing', 'unwanted', 'characters', 'and', 'normalizing', 'text', 'this', 'ensures', 'better', 'performance', 'in', 'tasks', 'like', 'sentiment', 'analysis', 'classification', 'or', 'language', 'modeling']\n"
     ]
    }
   ],
   "source": [
    "# 5.Remove Puntuation and symbols \n",
    "import string\n",
    "tokens_without_pun=[token for token in tokens if token not in string.punctuation]\n",
    "print(tokens_without_pun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73666c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
